# Prometheus ëª¨ë¸ë³„ P95 ë©”íŠ¸ë¦­ ì¡°íšŒ ê°€ì´ë“œ

## ê°œìš”

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Prometheusì—ì„œ AI ëª¨ë¸ë³„ P95 ë ˆì´í„´ì‹œ ë©”íŠ¸ë¦­ì„ ì¡°íšŒí•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

## ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. ë‹¨ìˆœ P95 ì¡°íšŒ

```bash
python query_p95_metrics.py --url http://localhost:9090
```

### 2. íŠ¹ì • ë©”íŠ¸ë¦­ ì¡°íšŒ

```bash
python query_p95_metrics.py --url http://localhost:9090 --metric api_latency_seconds
```

### 3. ì‹œê°„ ë²”ìœ„ ì§€ì •

```bash
python query_p95_metrics.py --url http://localhost:9090 --time-range 10m
```

### 4. ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ (Range Query)

```bash
python query_p95_metrics.py --url http://localhost:9090 --range 1h --step 5m
```

### 5. ì—¬ëŸ¬ ë°±ë¶„ìœ„ìˆ˜ ë™ì‹œ ì¡°íšŒ (P50, P95, P99)

```bash
python query_p95_metrics.py --url http://localhost:9090 --percentiles 50 95 99
```

### 6. JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

```bash
python query_p95_metrics.py --url http://localhost:9090 --json
```

## PromQL ì¿¼ë¦¬ ì˜ˆì‹œ

ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ PromQL ì¿¼ë¦¬:

### P95 ë ˆì´í„´ì‹œ (ëª¨ë¸ë³„)

```promql
histogram_quantile(0.95, 
  sum(rate(request_duration_seconds_bucket{job="api"}[5m])) 
  by (le, model)
)
```

### P99 ë ˆì´í„´ì‹œ (ëª¨ë¸ë³„)

```promql
histogram_quantile(0.99, 
  sum(rate(request_duration_seconds_bucket{job="api"}[5m])) 
  by (le, model)
)
```

### ëª¨ë¸ë³„ í‰ê·  ë ˆì´í„´ì‹œ

```promql
sum(rate(request_duration_seconds_sum{job="api"}[5m])) by (model)
/
sum(rate(request_duration_seconds_count{job="api"}[5m])) by (model)
```

### ëª¨ë¸ë³„ ìš”ì²­ ìˆ˜ (QPS)

```promql
sum(rate(request_duration_seconds_count{job="api"}[5m])) by (model)
```

## ì¶œë ¥ ì˜ˆì‹œ

```
============================================================
ğŸ“Š ëª¨ë¸ë³„ P95 ë ˆì´í„´ì‹œ ë©”íŠ¸ë¦­
============================================================

ğŸ¤– ëª¨ë¸: gpt-4               â†’ P95:   245.67ms
ğŸ¤– ëª¨ë¸: gpt-3.5-turbo       â†’ P95:   123.45ms
ğŸ¤– ëª¨ë¸: claude-2            â†’ P95:   189.23ms
ğŸ¤– ëª¨ë¸: palm-2              â†’ P95:   156.78ms

============================================================
```

## Python ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ê¸°

```python
from query_p95_metrics import PrometheusP95Query

# Prometheus í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
prom = PrometheusP95Query("http://localhost:9090")

# P95 ì¡°íšŒ
results = prom.query_p95_by_model(
    metric_name="request_duration_seconds",
    time_range="5m",
    model_label="model"
)

# ê²°ê³¼ ì¶œë ¥
prom.format_results(results)

# ì—¬ëŸ¬ ë°±ë¶„ìœ„ìˆ˜ ì¡°íšŒ
multi_results = prom.query_multiple_percentiles(
    metric_name="request_duration_seconds",
    percentiles=[0.50, 0.95, 0.99],
    time_range="5m"
)

for percentile, result in multi_results.items():
    prom.format_results(result, percentile)
```

## í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

### Prometheus ë©”íŠ¸ë¦­ êµ¬ì¡°

ìŠ¤í¬ë¦½íŠ¸ê°€ ì‘ë™í•˜ë ¤ë©´ Prometheusì— ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ì˜ íˆìŠ¤í† ê·¸ë¨ ë©”íŠ¸ë¦­ì´ í•„ìš”í•©ë‹ˆë‹¤:

```
# HELP request_duration_seconds Request duration in seconds
# TYPE request_duration_seconds histogram
request_duration_seconds_bucket{model="gpt-4",le="0.005"} 10
request_duration_seconds_bucket{model="gpt-4",le="0.01"} 25
request_duration_seconds_bucket{model="gpt-4",le="0.025"} 50
request_duration_seconds_bucket{model="gpt-4",le="0.05"} 100
request_duration_seconds_bucket{model="gpt-4",le="0.1"} 200
request_duration_seconds_bucket{model="gpt-4",le="0.25"} 450
request_duration_seconds_bucket{model="gpt-4",le="0.5"} 800
request_duration_seconds_bucket{model="gpt-4",le="1"} 950
request_duration_seconds_bucket{model="gpt-4",le="+Inf"} 1000
request_duration_seconds_sum{model="gpt-4"} 245.67
request_duration_seconds_count{model="gpt-4"} 1000
```

### Python í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë©”íŠ¸ë¦­ ìƒì„±

```python
from prometheus_client import Histogram, start_http_server

# íˆìŠ¤í† ê·¸ë¨ ë©”íŠ¸ë¦­ ì •ì˜
request_duration = Histogram(
    'request_duration_seconds',
    'Request duration in seconds',
    ['model'],
    buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

# ì‚¬ìš© ì˜ˆì‹œ
def process_request(model_name: str):
    with request_duration.labels(model=model_name).time():
        # ìš”ì²­ ì²˜ë¦¬ ë¡œì§
        pass

# Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘
start_http_server(8000)
```

## ê³ ê¸‰ ê¸°ëŠ¥

### ì»¤ìŠ¤í…€ ë ˆì´ë¸” ì‚¬ìš©

ëª¨ë¸ ì™¸ì— ë‹¤ë¥¸ ë ˆì´ë¸”ë¡œ ê·¸ë£¹í™”í•˜ë ¤ë©´:

```bash
python query_p95_metrics.py \
  --url http://localhost:9090 \
  --model-label "service" \
  --metric "http_request_duration_seconds"
```

### ëŒ€ì‹œë³´ë“œ ì—°ë™

Grafanaì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¿¼ë¦¬ í…œí”Œë¦¿:

```promql
# ë³€ìˆ˜: $model
histogram_quantile(0.95, 
  sum(rate(request_duration_seconds_bucket{model="$model"}[5m])) 
  by (le)
)
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì—°ê²° ì˜¤ë¥˜

```bash
# Prometheusê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
curl http://localhost:9090/-/healthy

# ë„¤íŠ¸ì›Œí¬ í™•ì¸
ping localhost
```

### ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°

1. ë©”íŠ¸ë¦­ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
2. ì‹œê°„ ë²”ìœ„ê°€ ë„ˆë¬´ ì¢ì§€ ì•Šì€ì§€ í™•ì¸
3. Prometheusì—ì„œ ì§ì ‘ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸:
   ```
   http://localhost:9090/graph
   ```

### ê¶Œí•œ ì˜¤ë¥˜

Prometheusì— ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš° ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ í—¤ë”ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:

```python
headers = {
    'Authorization': 'Bearer YOUR_TOKEN'
}

response = requests.get(
    f"{self.api_url}/query",
    params=params,
    headers=headers,
    timeout=10
)
```

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Prometheus ë¬¸ì„œ](https://prometheus.io/docs/)
- [PromQL ê°€ì´ë“œ](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Histogramê³¼ Summary](https://prometheus.io/docs/practices/histograms/)
