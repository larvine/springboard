# ê³ ê¸‰ ì‚¬ìš©ë²•

ì´ ê°€ì´ë“œì—ì„œëŠ” ê³ ê¸‰ ê¸°ëŠ¥ê³¼ ìµœì í™” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•„ë³¼ ìˆ˜ ìˆëŠ” ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

### Python ì˜ˆì œ

```python
import requests

def stream_response(prompt):
    response = requests.post(
        "https://api.example.com/v1/chat/stream",
        headers={"Authorization": f"Bearer {API_KEY}"},
        json={
            "model": "gpt-4",
            "messages": [{"role": "user", "content": prompt}],
            "stream": True
        },
        stream=True
    )
    
    for line in response.iter_lines():
        if line:
            print(line.decode('utf-8'))

stream_response("ê¸´ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”")
```

### JavaScript ì˜ˆì œ

```javascript
async function streamChat(prompt) {
  const response = await fetch('https://api.example.com/v1/chat/stream', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: [{role: 'user', content: prompt}],
      stream: true
    })
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const {done, value} = await reader.read();
    if (done) break;
    
    const chunk = decoder.decode(value);
    console.log(chunk);
  }
}
```

## í•¨ìˆ˜ í˜¸ì¶œ (Function Calling)

AI ëª¨ë¸ì´ íŠ¹ì • í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

### í•¨ìˆ˜ ì •ì˜

```python
functions = [
    {
        "name": "get_weather",
        "description": "íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {
                    "type": "string",
                    "description": "ë„ì‹œ ì´ë¦„ (ì˜ˆ: ì„œìš¸, ë¶€ì‚°)"
                },
                "unit": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "ì˜¨ë„ ë‹¨ìœ„"
                }
            },
            "required": ["city"]
        }
    }
]

response = requests.post(
    "https://api.example.com/v1/chat",
    headers={"Authorization": f"Bearer {API_KEY}"},
    json={
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?"}],
        "functions": functions
    }
)
```

## ë©€í‹°ëª¨ë‹¬ ì…ë ¥

ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

### ì´ë¯¸ì§€ URL ì‚¬ìš©

```python
response = requests.post(
    "https://api.example.com/v1/chat",
    headers={"Authorization": f"Bearer {API_KEY}"},
    json={
        "model": "gpt-4-vision",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?"},
                {"type": "image_url", "image_url": {
                    "url": "https://example.com/image.jpg"
                }}
            ]
        }]
    }
)
```

### Base64 ì´ë¯¸ì§€ ì‚¬ìš©

```python
import base64

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

base64_image = encode_image("photo.jpg")

response = requests.post(
    "https://api.example.com/v1/chat",
    headers={"Authorization": f"Bearer {API_KEY}"},
    json={
        "model": "gpt-4-vision",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "ì´ ì‚¬ì§„ ë¶„ì„í•´ì¤˜"},
                {"type": "image_url", "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }}
            ]
        }]
    }
)
```

## ë°°ì¹˜ ì²˜ë¦¬

ì—¬ëŸ¬ ìš”ì²­ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

```python
batch_requests = [
    {"custom_id": "req-1", "prompt": "1+1ì€?"},
    {"custom_id": "req-2", "prompt": "íŒŒì´ì¬ì´ë€?"},
    {"custom_id": "req-3", "prompt": "AIì˜ ë¯¸ë˜ëŠ”?"}
]

response = requests.post(
    "https://api.example.com/v1/batch",
    headers={"Authorization": f"Bearer {API_KEY}"},
    json={
        "model": "gpt-4",
        "requests": batch_requests
    }
)

# ë°°ì¹˜ ì‘ì—… ìƒíƒœ í™•ì¸
batch_id = response.json()["batch_id"]
status = requests.get(
    f"https://api.example.com/v1/batch/{batch_id}",
    headers={"Authorization": f"Bearer {API_KEY}"}
)
```

## ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹± í™œìš©

ë™ì¼í•œ ìš”ì²­ì— ëŒ€í•´ ìºì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ìš©ê³¼ ì‹œê°„ì„ ì ˆì•½:

```python
import hashlib
import json
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_request(prompt_hash):
    # API í˜¸ì¶œ
    pass

prompt = "ì•ˆë…•í•˜ì„¸ìš”"
prompt_hash = hashlib.md5(prompt.encode()).hexdigest()
result = cached_request(prompt_hash)
```

### 2. ë¹„ë™ê¸° ì²˜ë¦¬

ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬:

```python
import asyncio
import aiohttp

async def async_request(session, prompt):
    async with session.post(
        "https://api.example.com/v1/chat",
        headers={"Authorization": f"Bearer {API_KEY}"},
        json={"model": "gpt-4", "messages": [{"role": "user", "content": prompt}]}
    ) as response:
        return await response.json()

async def process_multiple():
    async with aiohttp.ClientSession() as session:
        tasks = [
            async_request(session, "ì§ˆë¬¸ 1"),
            async_request(session, "ì§ˆë¬¸ 2"),
            async_request(session, "ì§ˆë¬¸ 3")
        ]
        results = await asyncio.gather(*tasks)
        return results

results = asyncio.run(process_multiple())
```

### 3. í† í° ìµœì í™”

ë¶ˆí•„ìš”í•œ í† í° ì‚¬ìš©ì„ ì¤„ì´ëŠ” ë°©ë²•:

- í”„ë¡¬í”„íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ì‘ì„±
- `max_tokens` íŒŒë¼ë¯¸í„° ì ì ˆíˆ ì„¤ì •
- ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©

```python
# ì¢‹ì€ ì˜ˆ
messages = [
    {"role": "system", "content": "ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
    {"role": "user", "content": "AIë€?"}
]

# ë‚˜ìœ ì˜ˆ
messages = [
    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AIì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆì–´ì„œìš”. AIê°€ ì •í™•íˆ ë¬´ì—‡ì¸ì§€ ìì„¸í•˜ê³  ê¸¸ê²Œ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"}
]
```

## ì˜¤ë¥˜ ì²˜ë¦¬

ê²¬ê³ í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì˜¤ë¥˜ ì²˜ë¦¬ íŒ¨í„´:

```python
import time
from requests.exceptions import RequestException

def api_call_with_retry(prompt, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = requests.post(
                "https://api.example.com/v1/chat",
                headers={"Authorization": f"Bearer {API_KEY}"},
                json={
                    "model": "gpt-4",
                    "messages": [{"role": "user", "content": prompt}]
                },
                timeout=30
            )
            response.raise_for_status()
            return response.json()
            
        except RequestException as e:
            if attempt == max_retries - 1:
                raise
            wait_time = (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
            print(f"ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
            time.sleep(wait_time)
```

## ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ì‚¬ìš©ëŸ‰ ì¶”ì 

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def track_usage(response):
    usage = response.get('usage', {})
    logger.info(f"í† í° ì‚¬ìš©: {usage.get('total_tokens', 0)}")
    logger.info(f"ë¹„ìš©: ${usage.get('total_tokens', 0) * 0.00002:.4f}")
```

### ëŒ€ì‹œë³´ë“œ í™œìš©

ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”:

- ğŸ“Š [ì‚¬ìš©ëŸ‰ ëŒ€ì‹œë³´ë“œ](https://dashboard.example.com/usage)
- ğŸ’° [ë¹„ìš© ë¶„ì„](https://dashboard.example.com/billing)
- ğŸ” [ìš”ì²­ ë¡œê·¸](https://dashboard.example.com/logs)

---

**ë” ë§ì€ ì˜ˆì œì™€ ê³ ê¸‰ ê¸°ëŠ¥**ì€ [GitHub ì €ì¥ì†Œ](https://github.com/example/api-examples)ì—ì„œ í™•ì¸í•˜ì„¸ìš”.
